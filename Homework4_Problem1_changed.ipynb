{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305a0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bf8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('homework4_spikes.npz', 'rb') as loadfile:\n",
    "    spike_times = np.load(loadfile, allow_pickle=True)['spike_times']\n",
    "#     convert array into dataframe\n",
    "#     DF = pd.DataFrame(spike_times)\n",
    "#     # save the dataframe as a csv file\n",
    "#     DF.to_csv(\"HW4_spike_times.csv\")\n",
    "# print(DF.shape)\n",
    "\n",
    "with open('homework4_metadata.npy', 'rb') as loadfile:\n",
    "    metadata = np.load(loadfile)\n",
    "    time_touch_held = metadata['time_touch_held'] # target onset times for each trial\n",
    "    time_go_cue = metadata['time_go_cue'] # go cue time for each trial\n",
    "    time_target_acquired = metadata['time_target_acquired'] # time the target was touched\n",
    "    trial_reach_target = metadata['trial_reach_target'] # index of reach target for each trial (0 through 7)\n",
    "    # note that I've \"fixed\" the reach targets to be 0-7 rather than 1-8\n",
    "    target_locations = metadata['target_locations'] # x,y location of each target \n",
    "    target_angles = metadata['target_angles'] # angle of each target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3f976c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 755, 1005])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that there are in fact two different plan period durations\n",
    "np.unique(time_go_cue - time_touch_held)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e4fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_plan_spikes(window_length=None, \n",
    "                        start_offset=None):\n",
    "    # Return a matrix of spike counts in the plan window.\n",
    "    # - The default plan window is defined as the time between\n",
    "    #   time_touch_held and time_go_cue for each trial. NOTE:\n",
    "    #   not all trials have the same duration!!!\n",
    "    # - If a \"window_length\" is specified, return the number\n",
    "    #   of spikes in the window of that duration. Return -1\n",
    "    #   if the available plan period is too short for the window\n",
    "    #   (for example, window_length=1000 but the trial plan\n",
    "    #   period is just 755 ms). \n",
    "    # - If a \"start_offset\" is specified, return the number of\n",
    "    #   spikes in the window defined as starting \"start_offset\"\n",
    "    #   ms after the time_touch_held. (Use either time_go_cue\n",
    "    #   or the optional window_length to determine window end.)\n",
    "    #   If start_offset is so large that it extends past the\n",
    "    #   time_go_cue, return -1.\n",
    "    \n",
    "    if start_offset:\n",
    "        trial_starts = time_touch_held + start_offset\n",
    "    else:\n",
    "        trial_starts = time_touch_held\n",
    "    \n",
    "    plan_spikes = []   \n",
    "    for tx, trialSpikes in enumerate(spike_times):\n",
    "        if window_length:\n",
    "            trial_end = trial_starts[tx] + window_length\n",
    "        else:\n",
    "            trial_end = time_go_cue[tx]\n",
    "        \n",
    "        if (trial_end < trial_starts[tx]) or (trial_end > time_go_cue[tx]):\n",
    "                plan_spikes.append(-np.ones(len(trialSpikes)))\n",
    "        else:\n",
    "            plan_spikes.append(\n",
    "                np.array([np.sum((st > trial_starts[tx]) & \n",
    "                        (st < trial_end)) for st in trialSpikes]))\n",
    "    return np.array(plan_spikes) # will be 1127 x 190 (number of trials by number of neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba6ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 190)\n"
     ]
    }
   ],
   "source": [
    "plan_spikes = extract_plan_spikes(window_length=750)\n",
    "print(np.array(plan_spikes).shape)\n",
    "DF = pd.DataFrame(plan_spikes)\n",
    "DF.to_csv(\"plan_spikes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e1209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_trials (1127,)\n",
      "[False False False ...  True False False]\n",
      "Dimension of short trails\n",
      "Dimension of training trails (8, 25)\n",
      "[[ 118  504  172  247  865  198  981  804  122   86  560  410  348  720\n",
      "    46  758  168  276  428  331  293  817  860  337 1113]\n",
      " [ 540  177  459  734  277  181  323  532   90  446   10  124   30 1115\n",
      "    29  801  371   84    9  973  813  288 1109  144  959]\n",
      " [ 527  302  853  317   59  151  538  745  421  408  167   39  885  511\n",
      "    35  854   81  883  519 1073  829  976  694  722  837]\n",
      " [  95  646    7  926  693  766  284  759 1007  799   63  770  441  365\n",
      "   378  673  563  716  841  605  627  272  902  782  888]\n",
      " [ 611  847  958  516 1117  474  681  241  975  718  846  164  303  335\n",
      "   826  211  650  149 1000  219  412  769  366  396  201]\n",
      " [ 838  753  498   16  923  579  274  294 1028  619  170  904  859    2\n",
      "   567  591  557  158  174  295  843  266   25  899   82]\n",
      " [ 864  185  435  604  244  691 1008  787  222  363  148 1046  135  715\n",
      "   652  154  541  966  659   22 1072  561  566  986  520]\n",
      " [ 103  995  305 1031  737 1080  260  464  547  486  663  397  422 1075\n",
      "   772  287 1098  138  190  488  473  326   77 1014  434]]\n",
      "Dimension of test trails (927,)\n",
      "[  14   21   27   34   55   56   66   74   93   97  104  105  126  133\n",
      "  136  161  162  182  186  196  215  224  232  233  242  263  267  281\n",
      "  290  307  308  319  327  343  358  368  382  395  400  411  418  420\n",
      "  442  447  456  457  470  476  477  495  497  518  529  533  539  548\n",
      "  565  576  578  594  598  600  607  620  633  638  642  657  664  666\n",
      "  674  680  695  696  713  730  735  736  742  754  775  776  800  807\n",
      "  825  830  845  878  880  893  894  907  909  924  933  934  947  951\n",
      "  952  965  978  983 1001 1009 1022 1026 1036 1037 1053 1056 1062 1074\n",
      " 1084 1087 1095 1101 1123 1126    1   49   54   69   71   73   98  109\n",
      "  131  140  155  165  183  200  208  214  216  231  238  251  252  264\n",
      "  279  296  309  312  315  328  338  342  355  367  376  381  399  401\n",
      "  406  407  427  436  438  455  465  479  483  489  494  507  513  530\n",
      "  542  555  564  574  577  586  597  601  623  624  629  632  647  649\n",
      "  661  672  685  687  700  707  709  741  749  755  767  777  781  785\n",
      "  802  812  831  835  840  850  861  868  871  877  886  898  912  916\n",
      "  920  927  936  937  964  968  987  994  999 1003 1018 1023 1033 1044\n",
      " 1050 1060 1063 1069 1082 1086 1100 1102   13   18   44   47   61   78\n",
      "   91   94  106  113  134  145  157  160  176  192  194  204  210  213\n",
      "  218  236  237  245  255  259  280  282  289  292  299  325  336  339\n",
      "  350  356  362  370  379  380  393  394  419  431  432  448  454  458\n",
      "  463  472  485  500  501  514  543  553  558  572  581  593  595  603\n",
      "  610  614  626  635  640  648  654  662  665  677  684  699  706  711\n",
      "  729  739  760  762  779  780  789  790  791  797  818  822  848  869\n",
      "  895  896  908  914  921  930  938  949  953  961  974  990  996 1006\n",
      " 1010 1019 1025 1041 1043 1051 1057 1076 1081 1089 1106 1108 1110 1114\n",
      "    0   17   20   31   36   51   52   65   72   87  101  110  117  120\n",
      "  121  132  141  152  163  173  180  184  188  197  207  212  221  228\n",
      "  246  254  265  268  286  301  313  320  324  330  341  349  351  359\n",
      "  386  390  392  402  409  423  424  433  444  449  460  471  475  482\n",
      "  492  502  503  515  526  531  544  549  554  573  580  588  590  606\n",
      "  622  625  641  655  670  678  683  703  710  721  732  740  750  794\n",
      "  810  814  827  828  852  855  856  875  884  901  903  928  944  946\n",
      "  957  963  969  980  984  992 1012 1013 1015 1030 1032 1045 1052 1065\n",
      " 1070 1083 1091 1104 1105 1116 1119    3   11   19   32   37   41   42\n",
      "   64   70   75   83   88   99  108  115  127  128  137  139  153  169\n",
      "  171  189  191  203  229  239  250  258  262  269  283  297  311  316\n",
      "  321  334  352  354  369  374  383  388  405  425  426  437  439  443\n",
      "  452  462  466  480  491  499  509  523  524  535  536  552  562  568\n",
      "  575  583  589  602  615  616  628  656  668  671  686  692  704  708\n",
      "  723  726  743  748  756  765  783  786  796  798  809  819  823  863\n",
      "  866  872  874  887  890  905  906  918  929  939  941  955  979  988\n",
      "  993 1005 1016 1027 1029 1034 1048 1055 1066 1067 1078 1092 1097 1099\n",
      " 1121    8   12   33   43   48   62   67   80   92  102  114  116  123\n",
      "  129  142  205  206  225  230  240  248  273  300  306  322  345  357\n",
      "  372  377  387  416  417  429  445  468  481  487  510  512  521  528\n",
      "  545  546  559  596  608  613  631  636  644  651  660  669  675  688\n",
      "  697  698  712  719  724  727  744  747  763  768  771  788  792  805\n",
      "  811  816  836  839  857  873  876  900  913  931  942  945  954  962\n",
      "  971  977  989  991  997  998 1024 1035 1038 1049 1058 1061 1068 1077\n",
      " 1079 1093 1094 1120 1124    5    6   15   24   26   40   53   57   58\n",
      "   79   85  100  111  112  130  146  159  178  179  193  195  202  220\n",
      "  226  234  253  257  261  270  271  291  298  310  314  318  329  340\n",
      "  346  353  361  373  384  391  398  403  413  430  450  461  469  478\n",
      "  484  490  493  505  508  525  550  570  582  584  592  612  618  630\n",
      "  639  645  658  682  689  690  705  725  728  746  751  752  757  774\n",
      "  778  793  806  815  820  832  834  842  851  862  870  882  889  892\n",
      "  911  915  919  922  935  943  950  956  972  982 1011 1017 1021 1040\n",
      " 1042 1059 1071 1085 1088 1096 1107 1111 1122 1125    4   23   28   38\n",
      "   45   50   60   68   76   89   96  107  119  125  143  147  150  156\n",
      "  166  175  187  199  209  217  223  227  235  243  249  256  275  278\n",
      "  285  304  332  333  344  347  360  364  375  385  389  404  414  415\n",
      "  440  451  453  467  496  506  517  522  534  537  551  556  569  571\n",
      "  585  587  599  609  617  621  634  637  643  653  667  676  679  701\n",
      "  702  714  717  731  733  738  761  764  773  784  795  803  808  821\n",
      "  824  833  844  849  858  867  879  881  891  897  910  917  925  932\n",
      "  940  948  960  967  970  985 1002 1004 1020 1039 1047 1054 1064 1090\n",
      " 1103 1112 1118]\n"
     ]
    }
   ],
   "source": [
    "# select the 755 ms plan period trials for testing\n",
    "short_trials = (time_go_cue - time_touch_held) == 755 # boolean array\n",
    "print(\"short_trials\", np.array(short_trials).shape)\n",
    "print(short_trials)\n",
    "print(\"Dimension of short trails\")\n",
    "training_trials = [] # will be 8 lists of trials\n",
    "test_trials = [] # all the leftovers\n",
    "for c in range(8): # reach targets go from 0 to 7\n",
    "    target_trials = np.argwhere((trial_reach_target==c)).squeeze()\n",
    "    # randomly select 25 training trials per direction\n",
    "    random_training_trials = np.random.choice(target_trials, 25, replace=False)\n",
    "    training_trials.append(random_training_trials)\n",
    "    remaining_test_trials = np.setdiff1d(target_trials, random_training_trials)\n",
    "    \n",
    "    test_trials.extend(remaining_test_trials)\n",
    "\n",
    "arr1 = np.array(training_trials)\n",
    "arr2 = np.array(test_trials)\n",
    "print(\"Dimension of training trails\", arr1.shape)\n",
    "print(arr1)\n",
    "print(\"Dimension of test trails\", arr2.shape)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3cf5878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_neurons\n",
      "190\n",
      "mean_spike_counts\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "training_trials[c] at  0\n",
      "[ 118  504  172  247  865  198  981  804  122   86  560  410  348  720\n",
      "   46  758  168  276  428  331  293  817  860  337 1113]\n",
      "plan_spikes[training_trials[c],:] at  0\n",
      "[[ 0  1  3 ...  4 13  5]\n",
      " [ 0  3  4 ...  8 17  7]\n",
      " [ 0  1  2 ...  8  8  9]\n",
      " ...\n",
      " [ 0  3  2 ...  3  6  7]\n",
      " [ 2  1  1 ... 13  5  6]\n",
      " [ 1  5  0 ...  4 31 11]]\n",
      "mean_spike_counts at  0\n",
      "[[0.56 0.   0.   ... 0.   0.   0.  ]\n",
      " [3.4  0.   0.   ... 0.   0.   0.  ]\n",
      " [2.28 0.   0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [6.88 0.   0.   ... 0.   0.   0.  ]\n",
      " [8.72 0.   0.   ... 0.   0.   0.  ]\n",
      " [5.4  0.   0.   ... 0.   0.   0.  ]]\n",
      "training_trials[c] at  1\n",
      "[ 540  177  459  734  277  181  323  532   90  446   10  124   30 1115\n",
      "   29  801  371   84    9  973  813  288 1109  144  959]\n",
      "plan_spikes[training_trials[c],:] at  1\n",
      "[[2 5 3 ... 7 0 3]\n",
      " [5 6 1 ... 7 2 4]\n",
      " [0 5 0 ... 9 3 2]\n",
      " ...\n",
      " [0 3 3 ... 5 0 3]\n",
      " [0 1 1 ... 7 1 4]\n",
      " [0 3 2 ... 7 2 4]]\n",
      "mean_spike_counts at  1\n",
      "[[0.56 1.36 0.   ... 0.   0.   0.  ]\n",
      " [3.4  3.4  0.   ... 0.   0.   0.  ]\n",
      " [2.28 1.88 0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [6.88 7.   0.   ... 0.   0.   0.  ]\n",
      " [8.72 5.64 0.   ... 0.   0.   0.  ]\n",
      " [5.4  4.64 0.   ... 0.   0.   0.  ]]\n",
      "training_trials[c] at  2\n",
      "[ 527  302  853  317   59  151  538  745  421  408  167   39  885  511\n",
      "   35  854   81  883  519 1073  829  976  694  722  837]\n",
      "plan_spikes[training_trials[c],:] at  2\n",
      "[[ 0  2  1 ...  8  5  4]\n",
      " [ 0  5  4 ...  9  3  5]\n",
      " [ 2  4  1 ...  5  3  5]\n",
      " ...\n",
      " [ 1 10  3 ...  6  4  8]\n",
      " [ 4  7  8 ...  8  2  5]\n",
      " [ 0  1  4 ...  7  5  4]]\n",
      "mean_spike_counts at  2\n",
      "[[0.56 1.36 1.36 ... 0.   0.   0.  ]\n",
      " [3.4  3.4  3.92 ... 0.   0.   0.  ]\n",
      " [2.28 1.88 2.32 ... 0.   0.   0.  ]\n",
      " ...\n",
      " [6.88 7.   6.36 ... 0.   0.   0.  ]\n",
      " [8.72 5.64 5.44 ... 0.   0.   0.  ]\n",
      " [5.4  4.64 5.48 ... 0.   0.   0.  ]]\n",
      "training_trials[c] at  3\n",
      "[  95  646    7  926  693  766  284  759 1007  799   63  770  441  365\n",
      "  378  673  563  716  841  605  627  272  902  782  888]\n",
      "plan_spikes[training_trials[c],:] at  3\n",
      "[[ 0  6  0 ...  6  2  8]\n",
      " [ 2  1  2 ...  6  0  4]\n",
      " [ 0  3  2 ...  5  4 10]\n",
      " ...\n",
      " [ 0  1  0 ...  5  6  6]\n",
      " [ 0  8  6 ... 11  3  2]\n",
      " [ 3  5  0 ...  4  5  2]]\n",
      "mean_spike_counts at  3\n",
      "[[0.56 1.36 1.36 ... 0.   0.   0.  ]\n",
      " [3.4  3.4  3.92 ... 0.   0.   0.  ]\n",
      " [2.28 1.88 2.32 ... 0.   0.   0.  ]\n",
      " ...\n",
      " [6.88 7.   6.36 ... 0.   0.   0.  ]\n",
      " [8.72 5.64 5.44 ... 0.   0.   0.  ]\n",
      " [5.4  4.64 5.48 ... 0.   0.   0.  ]]\n",
      "training_trials[c] at  4\n",
      "[ 611  847  958  516 1117  474  681  241  975  718  846  164  303  335\n",
      "  826  211  650  149 1000  219  412  769  366  396  201]\n",
      "plan_spikes[training_trials[c],:] at  4\n",
      "[[5 6 2 ... 6 5 7]\n",
      " [0 5 3 ... 6 1 4]\n",
      " [1 5 5 ... 9 5 7]\n",
      " ...\n",
      " [0 2 1 ... 3 3 7]\n",
      " [0 9 1 ... 4 0 2]\n",
      " [3 8 4 ... 9 2 7]]\n",
      "mean_spike_counts at  4\n",
      "[[0.56 1.36 1.36 ... 0.   0.   0.  ]\n",
      " [3.4  3.4  3.92 ... 0.   0.   0.  ]\n",
      " [2.28 1.88 2.32 ... 0.   0.   0.  ]\n",
      " ...\n",
      " [6.88 7.   6.36 ... 0.   0.   0.  ]\n",
      " [8.72 5.64 5.44 ... 0.   0.   0.  ]\n",
      " [5.4  4.64 5.48 ... 0.   0.   0.  ]]\n",
      "training_trials[c] at  5\n",
      "[ 838  753  498   16  923  579  274  294 1028  619  170  904  859    2\n",
      "  567  591  557  158  174  295  843  266   25  899   82]\n",
      "plan_spikes[training_trials[c],:] at  5\n",
      "[[ 0  1  0 ...  7 13  4]\n",
      " [ 0  4  0 ...  4  8  9]\n",
      " [ 1  4  1 ...  4  2 12]\n",
      " ...\n",
      " [ 0  4  2 ...  6  9  9]\n",
      " [ 0  5  1 ...  7  3  7]\n",
      " [ 0  7  1 ...  8  3  3]]\n",
      "mean_spike_counts at  5\n",
      "[[0.56 1.36 1.36 ... 0.2  0.   0.  ]\n",
      " [3.4  3.4  3.92 ... 4.56 0.   0.  ]\n",
      " [2.28 1.88 2.32 ... 1.32 0.   0.  ]\n",
      " ...\n",
      " [6.88 7.   6.36 ... 6.   0.   0.  ]\n",
      " [8.72 5.64 5.44 ... 4.44 0.   0.  ]\n",
      " [5.4  4.64 5.48 ... 7.44 0.   0.  ]]\n",
      "training_trials[c] at  6\n",
      "[ 864  185  435  604  244  691 1008  787  222  363  148 1046  135  715\n",
      "  652  154  541  966  659   22 1072  561  566  986  520]\n",
      "plan_spikes[training_trials[c],:] at  6\n",
      "[[ 0  3  2 ...  5  1  2]\n",
      " [ 0  1  0 ...  3  2  9]\n",
      " [ 0  5  0 ...  4  7  7]\n",
      " ...\n",
      " [ 0  6  1 ...  7  0  6]\n",
      " [ 0  7  2 ...  8  9  9]\n",
      " [ 0  2  0 ...  9 12  7]]\n",
      "mean_spike_counts at  6\n",
      "[[0.56 1.36 1.36 ... 0.2  0.04 0.  ]\n",
      " [3.4  3.4  3.92 ... 4.56 4.52 0.  ]\n",
      " [2.28 1.88 2.32 ... 1.32 0.72 0.  ]\n",
      " ...\n",
      " [6.88 7.   6.36 ... 6.   6.76 0.  ]\n",
      " [8.72 5.64 5.44 ... 4.44 5.64 0.  ]\n",
      " [5.4  4.64 5.48 ... 7.44 5.92 0.  ]]\n",
      "training_trials[c] at  7\n",
      "[ 103  995  305 1031  737 1080  260  464  547  486  663  397  422 1075\n",
      "  772  287 1098  138  190  488  473  326   77 1014  434]\n",
      "plan_spikes[training_trials[c],:] at  7\n",
      "[[ 0  4  0 ...  5  8  1]\n",
      " [ 0  7  0 ...  2 10  4]\n",
      " [ 0  4  6 ...  7  7  6]\n",
      " ...\n",
      " [ 1  4  4 ... 11 15 11]\n",
      " [ 3 12  0 ...  5 15  3]\n",
      " [ 1  5  0 ...  5  2  6]]\n",
      "mean_spike_counts at  7\n",
      "[[0.56 1.36 1.36 ... 0.2  0.04 0.28]\n",
      " [3.4  3.4  3.92 ... 4.56 4.52 5.28]\n",
      " [2.28 1.88 2.32 ... 1.32 0.72 1.16]\n",
      " ...\n",
      " [6.88 7.   6.36 ... 6.   6.76 5.64]\n",
      " [8.72 5.64 5.44 ... 4.44 5.64 9.  ]\n",
      " [5.4  4.64 5.48 ... 7.44 5.92 5.68]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean spike counts per neuron for each target\n",
    "num_neurons = plan_spikes.shape[1]\n",
    "print(\"num_neurons\")\n",
    "print(num_neurons)\n",
    "mean_spike_counts = np.zeros((num_neurons, 8))\n",
    "print(\"mean_spike_counts\")\n",
    "print(mean_spike_counts)\n",
    "for c in range(8):\n",
    "    mean_spike_counts[:,c] = np.mean(plan_spikes[training_trials[c],:], axis=0)\n",
    "    print(\"training_trials[c] at \", c)\n",
    "    print(training_trials[c])\n",
    "    print(\"plan_spikes[training_trials[c],:] at \", c)\n",
    "    print(plan_spikes[training_trials[c],:])\n",
    "    print(\"mean_spike_counts at \", c)\n",
    "    print(mean_spike_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313a7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_poisson_logpdf(mu, x, mean_eps=0.01): \n",
    "    # assume mu is (N,) and x is (d,N)\n",
    "    mu2 = mu\n",
    "    mu2[np.argwhere(mu < mean_eps)] = mean_eps\n",
    "    return np.sum(x * np.log(mu) - mu, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c369b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability for each target and each test trial\n",
    "poisson_likelihood = np.zeros((len(test_trials), 8))    \n",
    "for c in range(8):\n",
    "    m = mean_spike_counts[:,c]\n",
    "    poisson_likelihood[:,c] = \\\n",
    "        multivariate_poisson_logpdf(m, plan_spikes[test_trials,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fa7a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson Correct:  0.9277238403451996\n",
      "(927 test trials)\n"
     ]
    }
   ],
   "source": [
    "correct_targets = trial_reach_target[test_trials] # correct target for each trial\n",
    "decoded_targets = np.argmax(poisson_likelihood,axis=1) # decoded target is just the max index\n",
    "print('Poisson Correct: ', np.mean(correct_targets==decoded_targets))\n",
    "print('({} test trials)'.format(len(test_trials)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151d4a67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (25,) (190,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m mean_spike_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_neurons, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#  2) calculate mean spike counts using training data\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# mean_spike_counts[:,c] = np.mean(plan_spikes[training_trials[c],:], axis=0)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     mean_spike_counts[:,c] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mplan_spikes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtraining_trials\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuron_idx\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     38\u001b[0m poisson_likelihood \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test_trials), \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (25,) (190,) "
     ]
    }
   ],
   "source": [
    "for offset in range(0, 500, 50):\n",
    "    decode_perf = []\n",
    "    for plan_window in np.arange(50,800,50): # (this goes to 750!!!)\n",
    "        plan_spikes = extract_plan_spikes(window_length=250, start_offset=offset)  #set the length of the decode window to 250 ms\n",
    "        # Before: plan_spikes = extract_plan_spikes(window_length=plan_window)\n",
    "        #  change your loop to loop over an offset variable that you design to range from 0 to 500 (500 is the maximum offset that will fit for the 755 ms plan windows!)\n",
    "        decode_perf.append([])\n",
    "    \n",
    "        # Randomly choose training and test data 25 times\n",
    "        for i in range(25): \n",
    "        \n",
    "            # Fill in code here to \n",
    "            #  1) randomly select training and test trials    \n",
    "\n",
    "            # randomly select 25 training trials per direction\n",
    "\n",
    "            training_trials = [] # will be 8 lists of trials\n",
    "            test_trials = [] # all the leftovers\n",
    "            for c in range(8): # reach targets go from 0 to 7\n",
    "                target_trials = np.argwhere((trial_reach_target==c)).squeeze()\n",
    "                # randomly select 25 training trials per direction\n",
    "                random_training_trials = np.random.choice(target_trials, 25, replace=False)\n",
    "                training_trials.append(random_training_trials)\n",
    "                remaining_test_trials = np.setdiff1d(target_trials, random_training_trials)\n",
    "\n",
    "                test_trials.extend(remaining_test_trials)\n",
    "            num_neurons = plan_spikes.shape[1]\n",
    "            mean_spike_counts = np.zeros((num_neurons, 8))\n",
    "            for c in range(8):\n",
    "                #  2) calculate mean spike counts using training data\n",
    "                mean_spike_counts[:,c] = np.mean(plan_spikes[training_trials[c],:], axis=0)\n",
    "\n",
    "            poisson_likelihood = np.zeros((len(test_trials), 8))\n",
    "            for c in range(8):\n",
    "                m = mean_spike_counts[:,c] \n",
    "                #  3) calculate target likelihoods for test data\n",
    "                poisson_likelihood[:,c] = multivariate_poisson_logpdf(m, plan_spikes[test_trials, :])\n",
    "\n",
    "            #  4) decode by picking the most likely target\n",
    "            correct_targets = trial_reach_target[test_trials]\n",
    "            decoded_targets = np.argmax(poisson_likelihood,axis=1)\n",
    "\n",
    "            # Assuming that you define the variables \"correct_targets\"\n",
    "            #  and \"decoded_targets\", the follow line calculates\n",
    "            #  the decoding performance for this iteration\n",
    "\n",
    "            decode_perf[-1].append(np.mean(correct_targets==decoded_targets))\n",
    "\n",
    "    decode_perf = np.array(decode_perf) # convert to a numpy array \n",
    "    #print(decode_perf)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = sns.violinplot(data = pd.DataFrame(np.array(decode_perf).T, \n",
    "                                  columns=np.arange(50,800,50)))\n",
    "    ax.set(xlabel='Plan Window Duration', ylabel='Decode Accuracy')\n",
    "    ax.set_ylim([0.7, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6e3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ae254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
